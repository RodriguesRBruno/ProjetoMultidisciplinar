{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9760a176",
   "metadata": {},
   "source": [
    "# Treinamento e validação de Modelos - Dataset Fake.br-Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a49e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from python_scripts.save_load import load_df_from_bucket, save_df_to_s3_bucket, save_to_s3_bucket_as_libsvm, BUCKET_MODEL\n",
    "from python_scripts.modelling import create_train_validation_test_sets, setup_model, make_prediction    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869007de",
   "metadata": {},
   "source": [
    "## Carregamento de dados\n",
    "Apenas as colunas de lemmas, tamanho médio de sentença e tamanho médio de palavra serão utilizadas no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc707e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake</th>\n",
       "      <th>text</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>words_str</th>\n",
       "      <th>lemmas_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A divisão do STF ao meio entre partidários e ...</td>\n",
       "      <td>10.504673</td>\n",
       "      <td>6.785107</td>\n",
       "      <td>divisão STF meio partidários independentes fic...</td>\n",
       "      <td>divisão STF meio partidário independente ficar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>General manda recado para STF: \"Abaixaram as c...</td>\n",
       "      <td>10.866667</td>\n",
       "      <td>6.502610</td>\n",
       "      <td>General manda recado STF Abaixaram calças Cong...</td>\n",
       "      <td>general mandar recado STF abaixar calça congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O Nordeste acordou! Lula e o PT são enxotados:...</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>6.565873</td>\n",
       "      <td>Nordeste acordou Lula PT enxotados Chega bande...</td>\n",
       "      <td>nordeste acordar Lula PT enxotar chegar bandei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Dois relatórios da Polícia Federal, com análi...</td>\n",
       "      <td>16.878788</td>\n",
       "      <td>7.286668</td>\n",
       "      <td>Dois relatórios Polícia Federal análises mater...</td>\n",
       "      <td>dois relatório Polícia Federal análise materia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Coreia do Norte declara status de QUASE-GUERRA...</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>6.531320</td>\n",
       "      <td>Coreia Norte declara status QUASE-GUERRA mobil...</td>\n",
       "      <td>Coreia Norte declarar status QUASE-GUERRA mobi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fake                                               text  avg_sent_len  \\\n",
       "0     0   A divisão do STF ao meio entre partidários e ...     10.504673   \n",
       "1     1  General manda recado para STF: \"Abaixaram as c...     10.866667   \n",
       "2     1  O Nordeste acordou! Lula e o PT são enxotados:...      7.333333   \n",
       "3     0   Dois relatórios da Polícia Federal, com análi...     16.878788   \n",
       "4     1  Coreia do Norte declara status de QUASE-GUERRA...     11.600000   \n",
       "\n",
       "   avg_word_len                                          words_str  \\\n",
       "0      6.785107  divisão STF meio partidários independentes fic...   \n",
       "1      6.502610  General manda recado STF Abaixaram calças Cong...   \n",
       "2      6.565873  Nordeste acordou Lula PT enxotados Chega bande...   \n",
       "3      7.286668  Dois relatórios Polícia Federal análises mater...   \n",
       "4      6.531320  Coreia Norte declara status QUASE-GUERRA mobil...   \n",
       "\n",
       "                                          lemmas_str  \n",
       "0  divisão STF meio partidário independente ficar...  \n",
       "1  general mandar recado STF abaixar calça congre...  \n",
       "2  nordeste acordar Lula PT enxotar chegar bandei...  \n",
       "3  dois relatório Polícia Federal análise materia...  \n",
       "4  Coreia Norte declarar status QUASE-GUERRA mobi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = load_df_from_bucket('dados_processados.csv', tipo='processado')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a03f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake</th>\n",
       "      <th>lemmas_str</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>divisão STF meio partidário independente ficar...</td>\n",
       "      <td>10.504673</td>\n",
       "      <td>6.785107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>general mandar recado STF abaixar calça congre...</td>\n",
       "      <td>10.866667</td>\n",
       "      <td>6.502610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nordeste acordar Lula PT enxotar chegar bandei...</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>6.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dois relatório Polícia Federal análise materia...</td>\n",
       "      <td>16.878788</td>\n",
       "      <td>7.286668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Coreia Norte declarar status QUASE-GUERRA mobi...</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>6.531320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fake                                         lemmas_str  avg_sent_len  \\\n",
       "0     0  divisão STF meio partidário independente ficar...     10.504673   \n",
       "1     1  general mandar recado STF abaixar calça congre...     10.866667   \n",
       "2     1  nordeste acordar Lula PT enxotar chegar bandei...      7.333333   \n",
       "3     0  dois relatório Polícia Federal análise materia...     16.878788   \n",
       "4     1  Coreia Norte declarar status QUASE-GUERRA mobi...     11.600000   \n",
       "\n",
       "   avg_word_len  \n",
       "0      6.785107  \n",
       "1      6.502610  \n",
       "2      6.565873  \n",
       "3      7.286668  \n",
       "4      6.531320  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = full_df[['fake', 'lemmas_str', 'avg_sent_len', 'avg_word_len']]\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28132d5b",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Modelo 1: Baseado em tamanho de sentenças e palavras\n",
    "\n",
    "O primeiro modelo treinado é um modelo mais simples. Aqui, apenas as colunas referentes ao tamanho médio de sentença e de palavra de cada artigo são consideradas, sem se levar em conta  o conteúdo da notícia propriamente dita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2691ace",
   "metadata": {},
   "source": [
    "### Separar dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f0353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, test_1, validate_1 = create_train_validation_test_sets(model_df.drop('lemmas_str', axis=1), \n",
    "                                                                stratify_col='fake',\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdca823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y_1(base_df, target_col='fake'):\n",
    "    return base_df.drop(target_col, axis=1), base_df[target_col]\n",
    "\n",
    "x_train_1, y_train_1 = create_x_y_1(train_1)\n",
    "x_validate_1, y_validate_1 = create_x_y_1(validate_1)\n",
    "x_test_1, y_test_1 = create_x_y_1(test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a03259",
   "metadata": {},
   "source": [
    "### Upload de dados para o S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c99d439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "file_name_tuples = [(x_train_1, y_train_1, 'train'), \n",
    "                   (x_test_1, y_test_1, 'test'), \n",
    "                   (x_validate_1, y_validate_1, 'validate')]\n",
    "\n",
    "for x, y, prefix in file_name_tuples:\n",
    "    save_to_s3_bucket_as_libsvm(x, y, prefix=prefix, filename='model_1.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254004e",
   "metadata": {},
   "source": [
    "### Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da26cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-11 23:30:14 Starting - Starting the training job...ProfilerReport-1668209414: InProgress\n",
      "...\n",
      "2022-11-11 23:31:08 Starting - Preparing the instances for training...............\n",
      "2022-11-11 23:33:46 Downloading - Downloading input data...\n",
      "2022-11-11 23:34:16 Training - Training image download completed. Training in progress....\u001b[35m[2022-11-11 23:34:31.893 ip-10-0-68-94.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[23:34:32] task NULL got new rank 0\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:32:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:32:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[34m[2022-11-11 23:34:29.987 ip-10-0-89-217.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] start listen on algo-1:9099\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9099}\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] No data received from connection ('10.0.89.217', 60984). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:31:INFO] No data received from connection ('10.0.68.94', 42896). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Recieve start signal from 10.0.68.94; assign rank 0\u001b[0m\n",
      "\u001b[34m[23:34:32] task NULL got new rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Recieve start signal from 10.0.89.217; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] @tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] @tracker 0.0019385814666748047 secs between node start and job finish\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] start listen on algo-1:9100\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9100}\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] No data received from connection ('10.0.89.217', 35162). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:35:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[23:34:35] task NULL got new rank 0\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:35:INFO] Train matrix has 5760 rows and 2 columns\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:35:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[35m[2022-11-11 23:34:35.433 ip-10-0-68-94.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] No data received from connection ('10.0.68.94', 50128). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Recieve start signal from 10.0.68.94; assign rank 0\u001b[0m\n",
      "\u001b[34m[23:34:35] task NULL got new rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Recieve start signal from 10.0.89.217; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] @tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Train matrix has 5760 rows and 2 columns\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[34m[2022-11-11 23:34:35.433 ip-10-0-89-217.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [0]#011train-auc:0.78137#011validation-auc:0.79978\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [1]#011train-auc:0.78679#011validation-auc:0.80471\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [2]#011train-auc:0.79106#011validation-auc:0.80726\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [3]#011train-auc:0.79414#011validation-auc:0.80991\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [4]#011train-auc:0.79599#011validation-auc:0.81083\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [5]#011train-auc:0.79735#011validation-auc:0.81005\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [6]#011train-auc:0.79936#011validation-auc:0.81068\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [7]#011train-auc:0.80113#011validation-auc:0.80918\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [8]#011train-auc:0.80242#011validation-auc:0.80960\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [9]#011train-auc:0.80454#011validation-auc:0.81049\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [10]#011train-auc:0.80915#011validation-auc:0.81056\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [11]#011train-auc:0.81057#011validation-auc:0.81100\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [12]#011train-auc:0.81385#011validation-auc:0.80779\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [13]#011train-auc:0.81671#011validation-auc:0.80572\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [14]#011train-auc:0.81910#011validation-auc:0.80460\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [15]#011train-auc:0.82128#011validation-auc:0.80442\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [16]#011train-auc:0.82379#011validation-auc:0.80388\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [17]#011train-auc:0.82656#011validation-auc:0.80461\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [18]#011train-auc:0.82912#011validation-auc:0.80674\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [19]#011train-auc:0.83184#011validation-auc:0.80475\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [20]#011train-auc:0.83393#011validation-auc:0.80222\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [21]#011train-auc:0.83589#011validation-auc:0.80159\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [22]#011train-auc:0.83720#011validation-auc:0.80153\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [23]#011train-auc:0.83899#011validation-auc:0.80141\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [24]#011train-auc:0.84070#011validation-auc:0.80172\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [25]#011train-auc:0.84297#011validation-auc:0.80324\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [26]#011train-auc:0.84447#011validation-auc:0.80363\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [27]#011train-auc:0.84752#011validation-auc:0.80236\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [28]#011train-auc:0.84910#011validation-auc:0.80291\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [29]#011train-auc:0.85037#011validation-auc:0.80225\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [30]#011train-auc:0.85212#011validation-auc:0.80107\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [31]#011train-auc:0.85384#011validation-auc:0.80186\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [32]#011train-auc:0.85589#011validation-auc:0.80139\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [33]#011train-auc:0.85758#011validation-auc:0.80093\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [34]#011train-auc:0.85856#011validation-auc:0.80144\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [35]#011train-auc:0.86116#011validation-auc:0.80095\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [36]#011train-auc:0.86211#011validation-auc:0.80089\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [37]#011train-auc:0.86288#011validation-auc:0.80048\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [38]#011train-auc:0.86385#011validation-auc:0.80048\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [39]#011train-auc:0.86578#011validation-auc:0.79921\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [40]#011train-auc:0.86634#011validation-auc:0.79910\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [41]#011train-auc:0.86867#011validation-auc:0.79773\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] @tracker 3.519244432449341 secs between node start and job finish\u001b[0m\n",
      "\n",
      "2022-11-11 23:35:06 Uploading - Uploading generated training model\n",
      "2022-11-11 23:35:06 Completed - Training job completed\n",
      "Training seconds: 154\n",
      "Billable seconds: 154\n",
      "ready for hosting!\n"
     ]
    }
   ],
   "source": [
    "xgb_model, data_channels = setup_model(base_image='xgboost', model_name='model_1', instance_count=2, \n",
    "                                       instance_type='ml.m4.xlarge')\n",
    "xgb_model.fit(inputs=data_channels)\n",
    "\n",
    "print('ready for hosting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0db16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                                 serializer=sagemaker.serializers.LibSVMSerializer(),\n",
    "                                 instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0ee3d",
   "metadata": {},
   "source": [
    "### Métricas no conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2287bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = make_prediction(xgb_predictor, model_name='model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d3934e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       360\n",
      "           1       0.68      0.67      0.68       360\n",
      "\n",
      "    accuracy                           0.68       720\n",
      "   macro avg       0.68      0.68      0.68       720\n",
      "weighted avg       0.68      0.68      0.68       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecd325",
   "metadata": {},
   "source": [
    "Modelo razoável dado sua simplicidade (ignora completamente o contexto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cdb3ae",
   "metadata": {},
   "source": [
    "### Salvar resultados de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d4f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_1 = pd.DataFrame({'pred_1': y_pred_1})\n",
    "df_pred_1.to_csv(f's3://{BUCKET_MODEL}/test/pred_1.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b1a56",
   "metadata": {},
   "source": [
    "### Encerrar modelo\n",
    "Após pegar métricas e dados de interesse, encerrar modelo para evitar cobranças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c04a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760302d",
   "metadata": {},
   "source": [
    "## Modelo 2: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d25bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2, test_2, validate_2 = create_train_validation_test_sets(model_df.drop(['avg_word_len', \n",
    "                                                                               'avg_sent_len'], axis=1), \n",
    "                                                                stratify_col='fake',\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6084859",
   "metadata": {},
   "source": [
    "### Processamento adicional\n",
    "\n",
    "Um vetorizador TFIDF é utilizado para converter os dados textuais em colunas do DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbc4328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(lowercase=False, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar vetorizador TFIDF e ajustar aos dados de treinamento\n",
    "tfidf = TfidfVectorizer(lowercase=False, ngram_range = (1,2))\n",
    "tfidf.fit(train_2['lemmas_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093c54ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y_2(base_df, tfidf, target_col='fake', lemma_col = 'lemmas_str'):\n",
    "    tfidf_res = tfidf.transform(base_df[lemma_col])\n",
    "    return tfidf_res, base_df[target_col]\n",
    "\n",
    "x_train_2, y_train_2 = create_x_y_2(train_2, tfidf)\n",
    "x_validate_2, y_validate_2 = create_x_y_2(validate_2, tfidf)\n",
    "x_test_2, y_test_2 = create_x_y_2(test_2, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c863b",
   "metadata": {},
   "source": [
    "### Upload de dados para o S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b229cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "file_name_tuples = [(x_train_2, y_train_2, 'train'), \n",
    "                   (x_test_2, y_test_2, 'test'), \n",
    "                   (x_validate_2, y_validate_2, 'validate')]\n",
    "\n",
    "for x, y, prefix in file_name_tuples:\n",
    "    save_to_s3_bucket_as_libsvm(x, y, prefix=prefix, filename='model_2.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7f456",
   "metadata": {},
   "source": [
    "### Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdc4ceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-14 20:40:13 Starting - Starting the training job...ProfilerReport-1668458413: InProgress\n",
      "...\n",
      "2022-11-14 20:40:57 Starting - Preparing the instances for training...............\n",
      "2022-11-14 20:43:37 Downloading - Downloading input data...\n",
      "2022-11-14 20:44:03 Training - Training image download completed. Training in progress.\u001b[32m[2022-11-14 20:44:05.440 ip-10-2-131-207.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[32mReturning the value itself\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[32mReturning the value itself\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] Distributed node training with 4 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4']\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:05:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[35m[2022-11-14 20:44:06.597 ip-10-2-135-97.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] Distributed node training with 4 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4']\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:06:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-14 20:44:05.812 ip-10-2-177-208.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:05:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:05:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:05:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:05:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:05:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:05:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:06:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:06:INFO] Distributed node training with 4 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4']\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:06:INFO] start listen on algo-1:9099\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:06:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9099}\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:06:INFO] No data received from connection ('10.2.177.208', 41888). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:06:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:06:INFO] No data received from connection ('10.2.135.97', 49170). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:08:INFO] No data received from connection ('10.2.131.207', 33430). Closing.\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:08:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] No data received from connection ('10.2.183.121', 41474). Closing.\u001b[0m\n",
      "\u001b[36m[2022-11-14 20:44:12.033 ip-10-2-183-121.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[36mReturning the value itself\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[36mReturning the value itself\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Distributed node training with 4 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4']\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[36m[20:44:12] task NULL got new rank 3\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:12:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] Recieve start signal from 10.2.131.207; assign rank 0\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] Recieve start signal from 10.2.135.97; assign rank 1\u001b[0m\n",
      "\u001b[34m[20:44:12] task NULL got new rank 2\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] Recieve start signal from 10.2.177.208; assign rank 2\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] Recieve start signal from 10.2.183.121; assign rank 3\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] @tracker All of 4 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] @tracker 0.04600024223327637 secs between node start and job finish\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] start listen on algo-1:9100\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9100}\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] No data received from connection ('10.2.177.208', 47878). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:12:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[32m[20:44:12] task NULL got new rank 0\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:12:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:12:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[35m[20:44:12] task NULL got new rank 1\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:12:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:12:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:15:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[36m[20:44:16] task NULL got new rank 3\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:16:INFO] Train matrix has 5760 rows and 1184676 columns\u001b[0m\n",
      "\u001b[36m[2022-11-14:20:44:16:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[36m[2022-11-14 20:44:16.217 ip-10-2-183-121.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:15:INFO] No data received from connection ('10.2.183.121', 58500). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:15:INFO] No data received from connection ('10.2.135.97', 47358). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:15:INFO] No data received from connection ('10.2.131.207', 36034). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:15:INFO] Recieve start signal from 10.2.131.207; assign rank 0\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:16:INFO] Recieve start signal from 10.2.135.97; assign rank 1\u001b[0m\n",
      "\u001b[34m[20:44:16] task NULL got new rank 2\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:16:INFO] Recieve start signal from 10.2.177.208; assign rank 2\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:16:INFO] Recieve start signal from 10.2.183.121; assign rank 3\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:16:INFO] @tracker All of 4 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:16:INFO] Train matrix has 5760 rows and 1184676 columns\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:44:16:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[34m[2022-11-14 20:44:16.217 ip-10-2-177-208.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:15:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[32m[20:44:15] task NULL got new rank 0\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:16:INFO] Train matrix has 5760 rows and 1184676 columns\u001b[0m\n",
      "\u001b[32m[2022-11-14:20:44:16:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[32m[2022-11-14 20:44:16.217 ip-10-2-131-207.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:15:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[20:44:15] task NULL got new rank 1\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:16:INFO] Train matrix has 5760 rows and 1184676 columns\u001b[0m\n",
      "\u001b[35m[2022-11-14:20:44:16:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[35m[2022-11-14 20:44:16.129 ip-10-2-135-97.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:45:14:INFO] [0]#011train-auc:0.96923#011validation-auc:0.95548\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:46:01:INFO] [1]#011train-auc:0.98488#011validation-auc:0.96512\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:46:47:INFO] [2]#011train-auc:0.99034#011validation-auc:0.97227\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:47:35:INFO] [3]#011train-auc:0.99242#011validation-auc:0.97639\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:48:18:INFO] [4]#011train-auc:0.99457#011validation-auc:0.97942\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:49:05:INFO] [5]#011train-auc:0.99600#011validation-auc:0.98478\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:49:51:INFO] [6]#011train-auc:0.99756#011validation-auc:0.98520\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:50:32:INFO] [7]#011train-auc:0.99794#011validation-auc:0.98665\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:51:16:INFO] [8]#011train-auc:0.99846#011validation-auc:0.98719\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:51:53:INFO] [9]#011train-auc:0.99878#011validation-auc:0.98947\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:52:36:INFO] [10]#011train-auc:0.99919#011validation-auc:0.99067\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:53:11:INFO] [11]#011train-auc:0.99920#011validation-auc:0.99214\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:53:52:INFO] [12]#011train-auc:0.99938#011validation-auc:0.99248\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:54:22:INFO] [13]#011train-auc:0.99945#011validation-auc:0.99337\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:54:52:INFO] [14]#011train-auc:0.99948#011validation-auc:0.99368\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:55:31:INFO] [15]#011train-auc:0.99957#011validation-auc:0.99373\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:56:05:INFO] [16]#011train-auc:0.99960#011validation-auc:0.99362\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:56:36:INFO] [17]#011train-auc:0.99959#011validation-auc:0.99395\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:57:04:INFO] [18]#011train-auc:0.99959#011validation-auc:0.99426\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:57:36:INFO] [19]#011train-auc:0.99961#011validation-auc:0.99436\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:58:03:INFO] [20]#011train-auc:0.99968#011validation-auc:0.99428\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:58:39:INFO] [21]#011train-auc:0.99988#011validation-auc:0.99426\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:59:09:INFO] [22]#011train-auc:0.99992#011validation-auc:0.99454\u001b[0m\n",
      "\u001b[34m[2022-11-14:20:59:40:INFO] [23]#011train-auc:0.99995#011validation-auc:0.99471\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:00:09:INFO] [24]#011train-auc:0.99997#011validation-auc:0.99489\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:00:42:INFO] [25]#011train-auc:0.99997#011validation-auc:0.99515\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:01:06:INFO] [26]#011train-auc:0.99997#011validation-auc:0.99535\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:01:39:INFO] [27]#011train-auc:0.99998#011validation-auc:0.99543\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:02:03:INFO] [28]#011train-auc:0.99998#011validation-auc:0.99542\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:02:27:INFO] [29]#011train-auc:0.99999#011validation-auc:0.99551\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:02:52:INFO] [30]#011train-auc:1.00000#011validation-auc:0.99532\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:03:15:INFO] [31]#011train-auc:1.00000#011validation-auc:0.99554\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:03:42:INFO] [32]#011train-auc:1.00000#011validation-auc:0.99562\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:04:11:INFO] [33]#011train-auc:1.00000#011validation-auc:0.99554\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:04:32:INFO] [34]#011train-auc:1.00000#011validation-auc:0.99581\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:04:56:INFO] [35]#011train-auc:1.00000#011validation-auc:0.99589\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:05:26:INFO] [36]#011train-auc:1.00000#011validation-auc:0.99576\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:05:51:INFO] [37]#011train-auc:1.00000#011validation-auc:0.99582\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:06:13:INFO] [38]#011train-auc:1.00000#011validation-auc:0.99590\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:06:35:INFO] [39]#011train-auc:1.00000#011validation-auc:0.99585\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:06:57:INFO] [40]#011train-auc:1.00000#011validation-auc:0.99599\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:07:26:INFO] [41]#011train-auc:1.00000#011validation-auc:0.99609\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:07:27:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-14:21:07:27:INFO] @tracker 1391.1150221824646 secs between node start and job finish\u001b[0m\n",
      "\n",
      "2022-11-14 21:08:24 Uploading - Uploading generated training model\n",
      "2022-11-14 21:08:24 Completed - Training job completed\n",
      "Training seconds: 6020\n",
      "Billable seconds: 6020\n",
      "ready for hosting!\n"
     ]
    }
   ],
   "source": [
    "xgb_model_2, data_channels_2 = setup_model(base_image='xgboost', model_name='model_2', instance_count=4, \n",
    "                                           instance_type='ml.m4.xlarge')\n",
    "xgb_model_2.fit(inputs=data_channels_2)\n",
    "\n",
    "print('ready for hosting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6758c675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor_2 = xgb_model_2.deploy(initial_instance_count=1,\n",
    "                                     serializer=sagemaker.serializers.LibSVMSerializer(),\n",
    "                                     instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e3d00",
   "metadata": {},
   "source": [
    "### Métricas do modelo\n",
    "O conjunto de testes é separado em duas partes para o teste, devido a limitações no tamanho de payload que podem ser enviadas ao endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2fe2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "half = test_2.shape[0]//2\n",
    "x_test_2_pt1, y_test_2_pt1 = create_x_y_2(test_2.iloc[:half], tfidf)\n",
    "x_test_2_pt2, y_test_2_pt2 = create_x_y_2(test_2.iloc[half:], tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ad66c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "save_to_s3_bucket_as_libsvm(x_test_2_pt1, y_test_2_pt1, prefix='test', \n",
    "                            filename='model_2_pt1.libsvm', tipo='modelo')\n",
    "save_to_s3_bucket_as_libsvm(x_test_2_pt2, y_test_2_pt2, prefix='test', \n",
    "                            filename='model_2_pt2.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd65e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "s3_path = f's3://projetointerdisciplinartreinoteste/test/model_2_pt1.libsvm'\n",
    "\n",
    "with fs.open(s3_path) as libsvm_file:\n",
    "    y_temp_1 = xgb_predictor_2.predict(libsvm_file)\n",
    "\n",
    "\n",
    "s3_path = f's3://projetointerdisciplinartreinoteste/test/model_2_pt2.libsvm'\n",
    "\n",
    "with fs.open(s3_path) as libsvm_file:\n",
    "    y_temp_2 = xgb_predictor_2.predict(libsvm_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdd8fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threhold de 0.5 para decidir classes\n",
    "y_pred_list_1 = [1 if float(x) >= 0.5 else 0 for x in y_temp_1.decode('utf-8').split('\\n') if x != '']\n",
    "y_pred_list_2 = [1 if float(x) >= 0.5 else 0 for x in y_temp_2.decode('utf-8').split('\\n') if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cbe1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = y_pred_list_1+y_pred_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12dd0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       360\n",
      "           1       0.94      0.97      0.95       360\n",
      "\n",
      "    accuracy                           0.95       720\n",
      "   macro avg       0.95      0.95      0.95       720\n",
      "weighted avg       0.95      0.95      0.95       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2bb2e",
   "metadata": {},
   "source": [
    "Resultados excelentes, muito acima do que seria razoavelmente esperado. Isto sugere problemas de *overfit* no dataset utilizado para a construção do modelo. Para testar a hipótese de *overfit*, posteriormente dados de teste serão amostrados do segundo dataset (FakeRecogna) para uma segunda validação deste modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69912cf",
   "metadata": {},
   "source": [
    "## Salvar resultados da predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8a1176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_2 = pd.DataFrame({'pred_2': y_pred_2})\n",
    "df_pred_2.to_csv(f's3://{BUCKET_MODEL}/test/pred_2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a70b8",
   "metadata": {},
   "source": [
    "## Teste adicional - Dataset FakeRecogna\n",
    "Serão amostradas 3500 notícias do Dataset FakeRecogna para uma segunda validação do presente modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c84d0",
   "metadata": {},
   "source": [
    "### Carregar dataset e amostrar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ea9de6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>lemmas_str</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entretenimento</td>\n",
       "      <td>apagão vaticano papar presar acusação tráfico ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saúde</td>\n",
       "      <td>governar equador anunciar preparar cova coleti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saúde</td>\n",
       "      <td>companhia air france operar voar direto pequim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saúde</td>\n",
       "      <td>marfrig global foods retomar vender carnar bov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entretenimento</td>\n",
       "      <td>assunto voltar compartilhar rede social julho ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Categoria                                         lemmas_str  fake\n",
       "0  entretenimento  apagão vaticano papar presar acusação tráfico ...     1\n",
       "1           saúde  governar equador anunciar preparar cova coleti...     0\n",
       "2           saúde  companhia air france operar voar direto pequim...     0\n",
       "3           saúde  marfrig global foods retomar vender carnar bov...     0\n",
       "4  entretenimento  assunto voltar compartilhar rede social julho ...     1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative_df = load_df_from_bucket('dados_processados_recogna.csv', tipo='processado')\n",
    "alternative_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "039a34a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>lemmas_str</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>saúde</td>\n",
       "      <td>urgente oms transmissão vírus chinês assintomá...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>entretenimento</td>\n",
       "      <td>imagem ciclista pelar praia vermelho urca zona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>mundo</td>\n",
       "      <td>circular rede social pandemia coronavírus orga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>política</td>\n",
       "      <td>pressionar respostar rápido efetivas crise eco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11589</th>\n",
       "      <td>saúde</td>\n",
       "      <td>vacinar desenvolvido covid19 capaz provocar câ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Categoria                                         lemmas_str  fake\n",
       "1271            saúde  urgente oms transmissão vírus chinês assintomá...     1\n",
       "4076   entretenimento  imagem ciclista pelar praia vermelho urca zona...     1\n",
       "10788           mundo  circular rede social pandemia coronavírus orga...     1\n",
       "11608        política  pressionar respostar rápido efetivas crise eco...     0\n",
       "11589           saúde  vacinar desenvolvido covid19 capaz provocar câ...     1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = alternative_df.sample(n=3500)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fcad1",
   "metadata": {},
   "source": [
    "#### Predição\n",
    "\n",
    "Aplicar TF-IDF para vetorizar, salvar dados no S3 e efetuar predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8491fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "x_test_alt, y_test_alt = create_x_y_2(sample_df, tfidf)\n",
    "save_to_s3_bucket_as_libsvm(x_test_alt, y_test_alt, \n",
    "                            prefix='test', filename='model_2_alt.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f182ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_alt = make_prediction(xgb_predictor_2, model_name='model_2_alt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c70d98",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78b883b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1698\n",
      "           1       0.52      1.00      0.68      1802\n",
      "\n",
      "    accuracy                           0.52      3500\n",
      "   macro avg       0.76      0.50      0.34      3500\n",
      "weighted avg       0.75      0.52      0.35      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_alt, y_pred_alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7b62f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporção de previsões de notícias falsas em y_pred_alt\n",
    "round(sum(y_pred_alt)/len(y_pred_alt), 4)  # 4 casas para ver que não foi TUDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "218c6f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporção de notícias realmente falsas nos dados de teste\n",
    "round(sample_df['fake'].sum()/sample_df.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dbf5a",
   "metadata": {},
   "source": [
    "Ao se testar o modelo no dataset FakeRecogna, os resultados obtidos foram muito ruins! O modelo simplesmente previu que praticamente todas as notícias do dataset seriam falsas. Uma hipótese do que pode ter levado a este resultado é a diferença nos termos utilizados nas notícias. O dataset FakeRecogna, por abrangir os anos de 2019 a 2021, apresenta um peso muito grande para termos relativos à pandemia de COVID-19 que se iniciou em 2020, e que não apareciam em grande quantidade no dataset Fake.br-Corpus.\n",
    "\n",
    "Um modelo treinado baseado no dataset FakeRecogna é apresentado no Notebook `model_fakerecogna.ipynb`, enquanto que um modelo baseado em ambos datasets é apresentado no notebook `model_fakebr.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442287d1",
   "metadata": {},
   "source": [
    "#### Salvar predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffa03925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_alt = pd.DataFrame({'pred_alt': y_pred_alt})\n",
    "df_pred_alt.to_csv(f's3://{BUCKET_MODEL}/test/pred_alt.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56079b80",
   "metadata": {},
   "source": [
    "### Encerrar modelo\n",
    "Após pegar métricas e dados de interesse, encerrar modelo para evitar cobranças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32f4563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor_2.delete_endpoint(delete_endpoint_config=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
