{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1784671",
   "metadata": {},
   "source": [
    "# Treinamento e validação de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f96b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from python_scripts.save_load import load_df_from_bucket, save_df_to_s3_bucket, save_to_s3_bucket_as_libsvm, BUCKET_MODEL\n",
    "from python_scripts.modelling import create_train_validation_test_sets, setup_model, make_prediction    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44fa09",
   "metadata": {},
   "source": [
    "### Processamento adicional\n",
    "Para utilizar os dados obtidos para treinamento de um modelo, algumas etapas adicionais de processamento serão executadas:\n",
    "- Apenas as colunas de lemmas, tamanho médio de sentença e tamanho médio de palavra serão utilizadas no modelo\n",
    "- Separação de dados de treino, validação e teste\n",
    "- Transformação TF-IDF será aplicada à coluna de lemmas\n",
    "- Colunas de tamanhos de sentenças e palavras serão padronizadas (ie RobustScaler para evitar problemas com outliers)\n",
    "- Salvar arquivos referentes aos dados de treino, validação e teste após este processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c041fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>words_str</th>\n",
       "      <th>lemmas_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A divisão do STF ao meio entre partidários e ...</td>\n",
       "      <td>['divisão', 'STF', 'meio', 'partidários', 'ind...</td>\n",
       "      <td>['divisão', 'STF', 'meio', 'partidário', 'inde...</td>\n",
       "      <td>10.747664</td>\n",
       "      <td>6.690641</td>\n",
       "      <td>divisão STF meio partidários independentes fic...</td>\n",
       "      <td>divisão STF meio partidário independente ficar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>General manda recado para STF: \"Abaixaram as c...</td>\n",
       "      <td>['General', 'manda', 'recado', 'STF', 'Abaixar...</td>\n",
       "      <td>['general', 'mandar', 'recado', 'STF', 'abaixa...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.461584</td>\n",
       "      <td>General manda recado STF Abaixaram calças Cong...</td>\n",
       "      <td>general mandar recado STF abaixar calça congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O Nordeste acordou! Lula e o PT são enxotados:...</td>\n",
       "      <td>['Nordeste', 'acordou', 'Lula', 'PT', 'enxotad...</td>\n",
       "      <td>['nordeste', 'acordar', 'Lula', 'PT', 'enxotar...</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>6.565873</td>\n",
       "      <td>Nordeste acordou Lula PT enxotados Chega bande...</td>\n",
       "      <td>nordeste acordar Lula PT enxotar chegar bandei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Dois relatórios da Polícia Federal, com análi...</td>\n",
       "      <td>['Dois', 'relatórios', 'Polícia', 'Federal', '...</td>\n",
       "      <td>['dois', 'relatório', 'Polícia', 'Federal', 'a...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.237319</td>\n",
       "      <td>Dois relatórios Polícia Federal análises mater...</td>\n",
       "      <td>dois relatório Polícia Federal análise materia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Coreia do Norte declara status de QUASE-GUERRA...</td>\n",
       "      <td>['Coreia', 'Norte', 'declara', 'status', 'QUAS...</td>\n",
       "      <td>['Coreia', 'Norte', 'declarar', 'status', 'QUA...</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>6.513799</td>\n",
       "      <td>Coreia Norte declara status QUASE-GUERRA mobil...</td>\n",
       "      <td>Coreia Norte declarar status QUASE-GUERRA mobi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fake                                               text  \\\n",
       "0     0   A divisão do STF ao meio entre partidários e ...   \n",
       "1     1  General manda recado para STF: \"Abaixaram as c...   \n",
       "2     1  O Nordeste acordou! Lula e o PT são enxotados:...   \n",
       "3     0   Dois relatórios da Polícia Federal, com análi...   \n",
       "4     1  Coreia do Norte declara status de QUASE-GUERRA...   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['divisão', 'STF', 'meio', 'partidários', 'ind...   \n",
       "1  ['General', 'manda', 'recado', 'STF', 'Abaixar...   \n",
       "2  ['Nordeste', 'acordou', 'Lula', 'PT', 'enxotad...   \n",
       "3  ['Dois', 'relatórios', 'Polícia', 'Federal', '...   \n",
       "4  ['Coreia', 'Norte', 'declara', 'status', 'QUAS...   \n",
       "\n",
       "                                              lemmas  avg_sent_len  \\\n",
       "0  ['divisão', 'STF', 'meio', 'partidário', 'inde...     10.747664   \n",
       "1  ['general', 'mandar', 'recado', 'STF', 'abaixa...     11.000000   \n",
       "2  ['nordeste', 'acordar', 'Lula', 'PT', 'enxotar...      7.333333   \n",
       "3  ['dois', 'relatório', 'Polícia', 'Federal', 'a...     17.000000   \n",
       "4  ['Coreia', 'Norte', 'declarar', 'status', 'QUA...     11.666667   \n",
       "\n",
       "   avg_word_len                                          words_str  \\\n",
       "0      6.690641  divisão STF meio partidários independentes fic...   \n",
       "1      6.461584  General manda recado STF Abaixaram calças Cong...   \n",
       "2      6.565873  Nordeste acordou Lula PT enxotados Chega bande...   \n",
       "3      7.237319  Dois relatórios Polícia Federal análises mater...   \n",
       "4      6.513799  Coreia Norte declara status QUASE-GUERRA mobil...   \n",
       "\n",
       "                                          lemmas_str  \n",
       "0  divisão STF meio partidário independente ficar...  \n",
       "1  general mandar recado STF abaixar calça congre...  \n",
       "2  nordeste acordar Lula PT enxotar chegar bandei...  \n",
       "3  dois relatório Polícia Federal análise materia...  \n",
       "4  Coreia Norte declarar status QUASE-GUERRA mobi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = load_df_from_bucket('dados_processados.csv', tipo='processado')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870a82ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake</th>\n",
       "      <th>lemmas_str</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>divisão STF meio partidário independente ficar...</td>\n",
       "      <td>10.747664</td>\n",
       "      <td>6.690641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>general mandar recado STF abaixar calça congre...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.461584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nordeste acordar Lula PT enxotar chegar bandei...</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>6.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dois relatório Polícia Federal análise materia...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.237319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Coreia Norte declarar status QUASE-GUERRA mobi...</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>6.513799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fake                                         lemmas_str  avg_sent_len  \\\n",
       "0     0  divisão STF meio partidário independente ficar...     10.747664   \n",
       "1     1  general mandar recado STF abaixar calça congre...     11.000000   \n",
       "2     1  nordeste acordar Lula PT enxotar chegar bandei...      7.333333   \n",
       "3     0  dois relatório Polícia Federal análise materia...     17.000000   \n",
       "4     1  Coreia Norte declarar status QUASE-GUERRA mobi...     11.666667   \n",
       "\n",
       "   avg_word_len  \n",
       "0      6.690641  \n",
       "1      6.461584  \n",
       "2      6.565873  \n",
       "3      7.237319  \n",
       "4      6.513799  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = full_df[['fake', 'lemmas_str', 'avg_sent_len', 'avg_word_len']]\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb8a09",
   "metadata": {},
   "source": [
    "## Modelo 1: Baseado em tamanho de sentenças e palavras\n",
    "\n",
    "O primeiro modelo treinado é um modelo mais simples. Aqui, apenas as colunas referentes ao tamanho médio de sentença e de palavra de cada artigo são consideradas, sem se levar em conta  o conteúdo da notícia propriamente dita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130458a5",
   "metadata": {},
   "source": [
    "### Separar dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f82c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, test_1, validate_1 = create_train_validation_test_sets(model_df.drop('lemmas_str', axis=1), \n",
    "                                                                stratify_col='fake',\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf26215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y_1(base_df, target_col='fake'):\n",
    "    return base_df.drop(target_col, axis=1), base_df[target_col]\n",
    "\n",
    "x_train_1, y_train_1 = create_x_y_1(train_1)\n",
    "x_validate_1, y_validate_1 = create_x_y_1(validate_1)\n",
    "x_test_1, y_test_1 = create_x_y_1(test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd361df",
   "metadata": {},
   "source": [
    "### Upload de dados para o S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d1b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "file_name_tuples = [(x_train_1, y_train_1, 'train'), \n",
    "                   (x_test_1, y_test_1, 'test'), \n",
    "                   (x_validate_1, y_validate_1, 'validate')]\n",
    "\n",
    "for x, y, prefix in file_name_tuples:\n",
    "    save_to_s3_bucket_as_libsvm(x, y, prefix=prefix, filename='model_1.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de472b",
   "metadata": {},
   "source": [
    "### Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80cbac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-11 23:30:14 Starting - Starting the training job...ProfilerReport-1668209414: InProgress\n",
      "...\n",
      "2022-11-11 23:31:08 Starting - Preparing the instances for training...............\n",
      "2022-11-11 23:33:46 Downloading - Downloading input data...\n",
      "2022-11-11 23:34:16 Training - Training image download completed. Training in progress....\u001b[35m[2022-11-11 23:34:31.893 ip-10-0-68-94.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:31:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[23:34:32] task NULL got new rank 0\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:32:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:32:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[34m[2022-11-11 23:34:29.987 ip-10-0-89-217.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] start listen on algo-1:9099\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9099}\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] No data received from connection ('10.0.89.217', 60984). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:30:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:31:INFO] No data received from connection ('10.0.68.94', 42896). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Recieve start signal from 10.0.68.94; assign rank 0\u001b[0m\n",
      "\u001b[34m[23:34:32] task NULL got new rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Recieve start signal from 10.0.89.217; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] @tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] @tracker 0.0019385814666748047 secs between node start and job finish\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] start listen on algo-1:9100\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9100}\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] No data received from connection ('10.0.89.217', 35162). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:32:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:35:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[23:34:35] task NULL got new rank 0\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:35:INFO] Train matrix has 5760 rows and 2 columns\u001b[0m\n",
      "\u001b[35m[2022-11-11:23:34:35:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[35m[2022-11-11 23:34:35.433 ip-10-0-68-94.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] No data received from connection ('10.0.68.94', 50128). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Recieve start signal from 10.0.68.94; assign rank 0\u001b[0m\n",
      "\u001b[34m[23:34:35] task NULL got new rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Recieve start signal from 10.0.89.217; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] @tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Train matrix has 5760 rows and 2 columns\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[34m[2022-11-11 23:34:35.433 ip-10-0-89-217.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [0]#011train-auc:0.78137#011validation-auc:0.79978\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [1]#011train-auc:0.78679#011validation-auc:0.80471\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [2]#011train-auc:0.79106#011validation-auc:0.80726\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [3]#011train-auc:0.79414#011validation-auc:0.80991\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [4]#011train-auc:0.79599#011validation-auc:0.81083\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [5]#011train-auc:0.79735#011validation-auc:0.81005\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [6]#011train-auc:0.79936#011validation-auc:0.81068\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [7]#011train-auc:0.80113#011validation-auc:0.80918\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:35:INFO] [8]#011train-auc:0.80242#011validation-auc:0.80960\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [9]#011train-auc:0.80454#011validation-auc:0.81049\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [10]#011train-auc:0.80915#011validation-auc:0.81056\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [11]#011train-auc:0.81057#011validation-auc:0.81100\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [12]#011train-auc:0.81385#011validation-auc:0.80779\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [13]#011train-auc:0.81671#011validation-auc:0.80572\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [14]#011train-auc:0.81910#011validation-auc:0.80460\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [15]#011train-auc:0.82128#011validation-auc:0.80442\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:36:INFO] [16]#011train-auc:0.82379#011validation-auc:0.80388\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [17]#011train-auc:0.82656#011validation-auc:0.80461\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [18]#011train-auc:0.82912#011validation-auc:0.80674\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [19]#011train-auc:0.83184#011validation-auc:0.80475\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [20]#011train-auc:0.83393#011validation-auc:0.80222\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [21]#011train-auc:0.83589#011validation-auc:0.80159\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [22]#011train-auc:0.83720#011validation-auc:0.80153\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [23]#011train-auc:0.83899#011validation-auc:0.80141\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [24]#011train-auc:0.84070#011validation-auc:0.80172\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:37:INFO] [25]#011train-auc:0.84297#011validation-auc:0.80324\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [26]#011train-auc:0.84447#011validation-auc:0.80363\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [27]#011train-auc:0.84752#011validation-auc:0.80236\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [28]#011train-auc:0.84910#011validation-auc:0.80291\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [29]#011train-auc:0.85037#011validation-auc:0.80225\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [30]#011train-auc:0.85212#011validation-auc:0.80107\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [31]#011train-auc:0.85384#011validation-auc:0.80186\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [32]#011train-auc:0.85589#011validation-auc:0.80139\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [33]#011train-auc:0.85758#011validation-auc:0.80093\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [34]#011train-auc:0.85856#011validation-auc:0.80144\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [35]#011train-auc:0.86116#011validation-auc:0.80095\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [36]#011train-auc:0.86211#011validation-auc:0.80089\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [37]#011train-auc:0.86288#011validation-auc:0.80048\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [38]#011train-auc:0.86385#011validation-auc:0.80048\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [39]#011train-auc:0.86578#011validation-auc:0.79921\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [40]#011train-auc:0.86634#011validation-auc:0.79910\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] [41]#011train-auc:0.86867#011validation-auc:0.79773\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-11:23:34:38:INFO] @tracker 3.519244432449341 secs between node start and job finish\u001b[0m\n",
      "\n",
      "2022-11-11 23:35:06 Uploading - Uploading generated training model\n",
      "2022-11-11 23:35:06 Completed - Training job completed\n",
      "Training seconds: 154\n",
      "Billable seconds: 154\n",
      "ready for hosting!\n"
     ]
    }
   ],
   "source": [
    "xgb_model, data_channels = setup_model(base_image='xgboost', model_name='model_1', instance_count=2, \n",
    "                                       instance_type='ml.m4.xlarge')\n",
    "xgb_model.fit(inputs=data_channels)\n",
    "\n",
    "print('ready for hosting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a4e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                                 serializer=sagemaker.serializers.LibSVMSerializer(),\n",
    "                                 instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca3f6e3",
   "metadata": {},
   "source": [
    "### Métricas no conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658b702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = make_prediction(xgb_predictor, model_name='model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89978e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       360\n",
      "           1       0.68      0.67      0.68       360\n",
      "\n",
      "    accuracy                           0.68       720\n",
      "   macro avg       0.68      0.68      0.68       720\n",
      "weighted avg       0.68      0.68      0.68       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eeb121",
   "metadata": {},
   "source": [
    "Modelo razoável dado sua simplicidade (ignora completamente o contexto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb78cf",
   "metadata": {},
   "source": [
    "### Salvar resultados de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e9bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_1 = pd.DataFrame({'pred_1': y_pred_1})\n",
    "df_pred_1.to_csv(f's3://{BUCKET_MODEL}/test/pred_1.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e7623",
   "metadata": {},
   "source": [
    "### Encerrar modelo\n",
    "Após pegar métricas e dados de interesse, encerrar modelo para evitar cobranças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b186e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f39b08",
   "metadata": {},
   "source": [
    "## Modelo 2: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2342e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2, test_2, validate_2 = create_train_validation_test_sets(model_df.drop(['avg_word_len', \n",
    "                                                                               'avg_sent_len'], axis=1), \n",
    "                                                                stratify_col='fake',\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc009b8",
   "metadata": {},
   "source": [
    "### Processamento adicional\n",
    "\n",
    "Um vetorizador TFIDF é utilizado para converter os dados textuais em colunas do DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d55cd421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(lowercase=False, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar vetorizador TFIDF e ajustar aos dados de treinamento\n",
    "tfidf = TfidfVectorizer(lowercase=False, ngram_range = (1,2))\n",
    "tfidf.fit(train_2['lemmas_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f27a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y_2(base_df, tfidf, target_col='fake', lemma_col = 'lemmas_str'):\n",
    "    tfidf_res = tfidf.transform(base_df[lemma_col])\n",
    "    return tfidf_res, base_df[target_col]\n",
    "\n",
    "x_train_2, y_train_2 = create_x_y_2(train_2, tfidf)\n",
    "x_validate_2, y_validate_2 = create_x_y_2(validate_2, tfidf)\n",
    "x_test_2, y_test_2 = create_x_y_2(test_2, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c093a34",
   "metadata": {},
   "source": [
    "### Upload de dados para o S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cab442c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "file_name_tuples = [(x_train_2, y_train_2, 'train'), \n",
    "                   (x_test_2, y_test_2, 'test'), \n",
    "                   (x_validate_2, y_validate_2, 'validate')]\n",
    "\n",
    "for x, y, prefix in file_name_tuples:\n",
    "    save_to_s3_bucket_as_libsvm(x, y, prefix=prefix, filename='model_2.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c56610",
   "metadata": {},
   "source": [
    "### Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "468e8de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 00:05:33 Starting - Starting the training job...ProfilerReport-1668211533: InProgress\n",
      "..................\n",
      "2022-11-12 00:08:47 Starting - Preparing the instances for training.....................\n",
      "2022-11-12 00:12:34 Downloading - Downloading input data.....\u001b[34m[2022-11-12 00:13:17.428 ip-10-2-89-124.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] Distributed node training with 6 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4', 'algo-5', 'algo-6']\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:17:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[32m[2022-11-12 00:13:19.384 ip-10-2-79-192.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[32mReturning the value itself\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[32mReturning the value itself\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] Distributed node training with 6 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4', 'algo-5', 'algo-6']\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:19:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[35m[2022-11-12 00:13:19.892 ip-10-2-117-132.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:19:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:19:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:19:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:19:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:19:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:20:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:20:INFO] Distributed node training with 6 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4', 'algo-5', 'algo-6']\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:20:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:20:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:20:INFO] Failed to connect to RabitTracker on attempt 1\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:20:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:22:INFO] Failed to connect to RabitTracker on attempt 1\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:22:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:23:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\n",
      "2022-11-12 00:13:29 Training - Training image download completed. Training in progress.\u001b[33m[2022-11-12 00:13:19.756 ip-10-2-124-125.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:19:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:19:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[33mReturning the value itself\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:19:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[33mReturning the value itself\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:19:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:19:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:20:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:20:INFO] Distributed node training with 6 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4', 'algo-5', 'algo-6']\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:20:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:20:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:23:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:23:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:25:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[36m[00:13:25] task NULL got new rank 0\u001b[0m\n",
      "\u001b[36m[2022-11-12:00:13:26:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[36m[2022-11-12:00:13:26:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[32m[00:13:26] task NULL got new rank 5\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:26:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:26:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[33m[00:13:25] task NULL got new rank 1\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:26:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:26:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[34m[2022-11-12 00:13:22.369 ip-10-2-76-126.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] Distributed node training with 6 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4', 'algo-5', 'algo-6']\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] start listen on algo-1:9099\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9099}\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] No data received from connection ('10.2.76.126', 55160). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:22:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:23:INFO] No data received from connection ('10.2.124.125', 59176). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:23:INFO] No data received from connection ('10.2.117.132', 50904). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:23:INFO] No data received from connection ('10.2.89.124', 49544). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:24:INFO] No data received from connection ('10.2.72.157', 36162). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:25:INFO] No data received from connection ('10.2.79.192', 56170). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:25:INFO] Recieve start signal from 10.2.117.132; assign rank 0\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:25:INFO] Recieve start signal from 10.2.124.125; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Recieve start signal from 10.2.72.157; assign rank 2\u001b[0m\n",
      "\u001b[34m[00:13:26] task NULL got new rank 3\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Recieve start signal from 10.2.76.126; assign rank 3\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Recieve start signal from 10.2.79.192; assign rank 4\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Recieve start signal from 10.2.89.124; assign rank 5\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] @tracker All of 6 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] @tracker 0.13301825523376465 secs between node start and job finish\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] start listen on algo-1:9100\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9100}\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] No data received from connection ('10.2.76.126', 52868). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[00:13:26] task NULL got new rank 4\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:26:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[35m[2022-11-12 00:13:23.840 ip-10-2-72-157.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:23:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:23:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:23:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:23:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:23:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:23:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:24:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:24:INFO] Distributed node training with 6 hosts: ['algo-1', 'algo-2', 'algo-3', 'algo-4', 'algo-5', 'algo-6']\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:24:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[00:13:25] task NULL got new rank 2\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:26:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:26:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[36m[2022-11-12:00:13:29:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:29:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:29:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:29:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] No data received from connection ('10.2.117.132', 40808). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] No data received from connection ('10.2.89.124', 49152). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] No data received from connection ('10.2.79.192', 52846). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] No data received from connection ('10.2.124.125', 42628). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] No data received from connection ('10.2.72.157', 60532). Closing.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Recieve start signal from 10.2.117.132; assign rank 0\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Recieve start signal from 10.2.124.125; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Recieve start signal from 10.2.72.157; assign rank 2\u001b[0m\n",
      "\u001b[34m[00:13:29] task NULL got new rank 3\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Recieve start signal from 10.2.76.126; assign rank 3\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[00:13:29] task NULL got new rank 4\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Train matrix has 5760 rows and 1177739 columns\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[34m[2022-11-12 00:13:29.988 ip-10-2-79-192.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[36m[00:13:29] task NULL got new rank 0\u001b[0m\n",
      "\u001b[36m[2022-11-12:00:13:29:INFO] Train matrix has 5760 rows and 1177739 columns\u001b[0m\n",
      "\u001b[36m[2022-11-12:00:13:29:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[36m[2022-11-12 00:13:29.988 ip-10-2-117-132.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[32m[00:13:29] task NULL got new rank 5\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:29:INFO] Train matrix has 5760 rows and 1177739 columns\u001b[0m\n",
      "\u001b[32m[2022-11-12:00:13:29:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[32m[2022-11-12 00:13:29.988 ip-10-2-89-124.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[33m[00:13:29] task NULL got new rank 1\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:29:INFO] Train matrix has 5760 rows and 1177739 columns\u001b[0m\n",
      "\u001b[33m[2022-11-12:00:13:29:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[33m[2022-11-12 00:13:29.810 ip-10-2-124-125.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[00:13:29] task NULL got new rank 2\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:29:INFO] Train matrix has 5760 rows and 1177739 columns\u001b[0m\n",
      "\u001b[35m[2022-11-12:00:13:29:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[35m[2022-11-12 00:13:29.810 ip-10-2-72-157.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Recieve start signal from 10.2.79.192; assign rank 4\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Train matrix has 5760 rows and 1177739 columns\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Validation matrix has 720 rows\u001b[0m\n",
      "\u001b[34m[2022-11-12 00:13:29.900 ip-10-2-76-126.ec2.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] Recieve start signal from 10.2.89.124; assign rank 5\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:13:29:INFO] @tracker All of 6 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:14:35:INFO] [0]#011train-auc:0.96939#011validation-auc:0.95499\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:15:22:INFO] [1]#011train-auc:0.98364#011validation-auc:0.96957\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:16:12:INFO] [2]#011train-auc:0.98967#011validation-auc:0.97423\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:17:06:INFO] [3]#011train-auc:0.99272#011validation-auc:0.97498\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:17:58:INFO] [4]#011train-auc:0.99540#011validation-auc:0.97837\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:18:49:INFO] [5]#011train-auc:0.99618#011validation-auc:0.98099\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:19:36:INFO] [6]#011train-auc:0.99700#011validation-auc:0.98402\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:20:26:INFO] [7]#011train-auc:0.99761#011validation-auc:0.98633\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:21:16:INFO] [8]#011train-auc:0.99843#011validation-auc:0.98699\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:22:04:INFO] [9]#011train-auc:0.99897#011validation-auc:0.98793\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:22:50:INFO] [10]#011train-auc:0.99921#011validation-auc:0.98916\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:23:31:INFO] [11]#011train-auc:0.99922#011validation-auc:0.99000\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:24:04:INFO] [12]#011train-auc:0.99932#011validation-auc:0.99069\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:24:43:INFO] [13]#011train-auc:0.99948#011validation-auc:0.99072\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:25:19:INFO] [14]#011train-auc:0.99955#011validation-auc:0.99165\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:25:54:INFO] [15]#011train-auc:0.99982#011validation-auc:0.99217\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:26:24:INFO] [16]#011train-auc:0.99983#011validation-auc:0.99245\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:26:57:INFO] [17]#011train-auc:0.99989#011validation-auc:0.99224\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:27:31:INFO] [18]#011train-auc:0.99989#011validation-auc:0.99254\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:28:06:INFO] [19]#011train-auc:0.99991#011validation-auc:0.99267\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:28:43:INFO] [20]#011train-auc:0.99992#011validation-auc:0.99282\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:29:15:INFO] [21]#011train-auc:0.99996#011validation-auc:0.99286\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:29:47:INFO] [22]#011train-auc:0.99996#011validation-auc:0.99348\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:30:19:INFO] [23]#011train-auc:0.99999#011validation-auc:0.99385\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:30:47:INFO] [24]#011train-auc:0.99999#011validation-auc:0.99401\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:31:16:INFO] [25]#011train-auc:1.00000#011validation-auc:0.99416\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:31:53:INFO] [26]#011train-auc:1.00000#011validation-auc:0.99416\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:32:31:INFO] [27]#011train-auc:1.00000#011validation-auc:0.99428\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:33:05:INFO] [28]#011train-auc:1.00000#011validation-auc:0.99401\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:33:36:INFO] [29]#011train-auc:1.00000#011validation-auc:0.99392\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:34:09:INFO] [30]#011train-auc:1.00000#011validation-auc:0.99412\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:34:40:INFO] [31]#011train-auc:1.00000#011validation-auc:0.99381\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:35:04:INFO] [32]#011train-auc:1.00000#011validation-auc:0.99377\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:35:39:INFO] [33]#011train-auc:1.00000#011validation-auc:0.99412\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:36:10:INFO] [34]#011train-auc:1.00000#011validation-auc:0.99464\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:36:32:INFO] [35]#011train-auc:1.00000#011validation-auc:0.99469\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:36:59:INFO] [36]#011train-auc:1.00000#011validation-auc:0.99467\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:37:23:INFO] [37]#011train-auc:1.00000#011validation-auc:0.99471\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:37:52:INFO] [38]#011train-auc:1.00000#011validation-auc:0.99501\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:38:20:INFO] [39]#011train-auc:1.00000#011validation-auc:0.99529\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:38:48:INFO] [40]#011train-auc:1.00000#011validation-auc:0.99545\u001b[0m\n",
      "\n",
      "2022-11-12 00:39:21 Uploading - Uploading generated training model\u001b[34m[2022-11-12:00:39:14:INFO] [41]#011train-auc:1.00000#011validation-auc:0.99535\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:39:14:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-11-12:00:39:14:INFO] @tracker 1544.8105964660645 secs between node start and job finish\u001b[0m\n",
      "\n",
      "2022-11-12 00:39:56 Completed - Training job completed\n",
      "ProfilerReport-1668211533: NoIssuesFound\n",
      "Training seconds: 9708\n",
      "Billable seconds: 9708\n",
      "ready for hosting!\n"
     ]
    }
   ],
   "source": [
    "xgb_model_2, data_channels_2 = setup_model(base_image='xgboost', model_name='model_2', instance_count=4, \n",
    "                                           instance_type='ml.m4.xlarge')\n",
    "xgb_model_2.fit(inputs=data_channels_2)\n",
    "\n",
    "print('ready for hosting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faaba5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor_2 = xgb_model_2.deploy(initial_instance_count=1,\n",
    "                                     serializer=sagemaker.serializers.LibSVMSerializer(),\n",
    "                                     instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef5594",
   "metadata": {},
   "source": [
    "### Métricas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muito grande! Ver algo de batch ou como customizar tamanho máximo de payload. \n",
    "# Por ora, fazer tosquice pra contonar e obter resultados preliminares\n",
    "# y_pred_2 = make_prediction(xgb_predictor_2, model_name='model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62191b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "half = test_2.shape[0]//2\n",
    "x_test_2_pt1, y_test_2_pt1 = create_x_y_2(test_2.iloc[:half], tfidf)\n",
    "x_test_2_pt2, y_test_2_pt2 = create_x_y_2(test_2.iloc[half:], tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69a3a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "save_to_s3_bucket_as_libsvm(x_test_2_pt1, y_test_2_pt1, prefix='test', \n",
    "                            filename='model_2_pt1.libsvm', tipo='modelo')\n",
    "save_to_s3_bucket_as_libsvm(x_test_2_pt2, y_test_2_pt2, prefix='test', \n",
    "                            filename='model_2_pt2.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c4ed347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "s3_path = f's3://projetointerdisciplinartreinoteste/test/model_2_pt1.libsvm'\n",
    "\n",
    "with fs.open(s3_path) as libsvm_file:\n",
    "    y_temp_1 = xgb_predictor_2.predict(libsvm_file)\n",
    "\n",
    "\n",
    "s3_path = f's3://projetointerdisciplinartreinoteste/test/model_2_pt2.libsvm'\n",
    "\n",
    "with fs.open(s3_path) as libsvm_file:\n",
    "    y_temp_2 = xgb_predictor_2.predict(libsvm_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4edd56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list_1 = [1 if float(x) >= 0.5 else 0 for x in y_temp_1.decode('utf-8').split('\\n') if x != '']\n",
    "y_pred_list_2 = [1 if float(x) >= 0.5 else 0 for x in y_temp_2.decode('utf-8').split('\\n') if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "608bee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = y_pred_list_1+y_pred_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e9403e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       360\n",
      "           1       0.94      0.98      0.96       360\n",
      "\n",
      "    accuracy                           0.96       720\n",
      "   macro avg       0.96      0.96      0.96       720\n",
      "weighted avg       0.96      0.96      0.96       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d8a2e",
   "metadata": {},
   "source": [
    "## TODO arrumar comentários\n",
    "Resultados excelentes, diria até suspeitos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b396f7",
   "metadata": {},
   "source": [
    "## Salvar resultados da predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70c6f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_2 = pd.DataFrame({'pred_2': y_pred_2})\n",
    "df_pred_2.to_csv(f's3://{BUCKET_MODEL}/test/pred_2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cfe839",
   "metadata": {},
   "source": [
    "## Teste adicional - Segundo dataset\n",
    "Um segundo dataset de notícias também foi encontrado: https://github.com/Gabriel-Lino-Garcia/FakeRecogna\n",
    "Para validar os excelentes resultados obtido no teste com o dataset original, o modelo também foi testado neste dataset.\n",
    "\n",
    "Os dados deste dataset já vem no formato de lemma e sem stopwords, de forma que o vetorizador TFIDF pode ser aplicado diretamente a ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52b0ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Subtitulo</th>\n",
       "      <th>Noticia</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Data</th>\n",
       "      <th>Autor</th>\n",
       "      <th>URL</th>\n",
       "      <th>Classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nPapa Francisco foi preso sob acusação de t...</td>\n",
       "      <td>Boato – Ocorreu um apagão no Vaticano. O papa ...</td>\n",
       "      <td>apagão vaticano papar presar acusação tráfico ...</td>\n",
       "      <td>entretenimento</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>\\nEdgard Matsuki</td>\n",
       "      <td>https://www.boatos.org/religiao/papa-francisco...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Equador prepara cova coletiva para mortos por ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o governar equador anunciar preparar cova cole...</td>\n",
       "      <td>saúde</td>\n",
       "      <td>27/03/2020 18h25</td>\n",
       "      <td>27/03/2020 18h25</td>\n",
       "      <td>https://noticias.uol.com.br/internacional/ulti...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air France voltará a operar voo direto Pequim-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o companhia air france operar voar direto pequ...</td>\n",
       "      <td>saúde</td>\n",
       "      <td>07/08/2020 13h42</td>\n",
       "      <td>07/08/2020 13h42</td>\n",
       "      <td>https://www.uol.com.br/nossa/noticias/afp/2020...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marfrig intensifica venda de carne do Brasil a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o marfrig global foods retomar vender carnar b...</td>\n",
       "      <td>saúde</td>\n",
       "      <td>27/04/2020 14h53</td>\n",
       "      <td>27/04/2020 14h53</td>\n",
       "      <td>https://economia.uol.com.br/noticias/reuters/2...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As parciais das eleições de 2014 alternaram ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o assunto voltar o compartilhar rede social ju...</td>\n",
       "      <td>entretenimento</td>\n",
       "      <td>31/07/2021</td>\n",
       "      <td>Gilmar Lopes</td>\n",
       "      <td>https://www.e-farsas.com/as-parciais-das-eleic...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titulo  \\\n",
       "0  \\n\\nPapa Francisco foi preso sob acusação de t...   \n",
       "1  Equador prepara cova coletiva para mortos por ...   \n",
       "2  Air France voltará a operar voo direto Pequim-...   \n",
       "3  Marfrig intensifica venda de carne do Brasil a...   \n",
       "4  As parciais das eleições de 2014 alternaram ma...   \n",
       "\n",
       "                                           Subtitulo  \\\n",
       "0  Boato – Ocorreu um apagão no Vaticano. O papa ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             Noticia       Categoria  \\\n",
       "0  apagão vaticano papar presar acusação tráfico ...  entretenimento   \n",
       "1  o governar equador anunciar preparar cova cole...           saúde   \n",
       "2  o companhia air france operar voar direto pequ...           saúde   \n",
       "3  o marfrig global foods retomar vender carnar b...           saúde   \n",
       "4  o assunto voltar o compartilhar rede social ju...  entretenimento   \n",
       "\n",
       "                Data              Autor  \\\n",
       "0         11/01/2021  \\nEdgard Matsuki    \n",
       "1  27/03/2020 18h25   27/03/2020 18h25    \n",
       "2  07/08/2020 13h42   07/08/2020 13h42    \n",
       "3  27/04/2020 14h53   27/04/2020 14h53    \n",
       "4         31/07/2021       Gilmar Lopes   \n",
       "\n",
       "                                                 URL  Classe  \n",
       "0  https://www.boatos.org/religiao/papa-francisco...     0.0  \n",
       "1  https://noticias.uol.com.br/internacional/ulti...     1.0  \n",
       "2  https://www.uol.com.br/nossa/noticias/afp/2020...     1.0  \n",
       "3  https://economia.uol.com.br/noticias/reuters/2...     1.0  \n",
       "4  https://www.e-farsas.com/as-parciais-das-eleic...     0.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_link = 'https://github.com/Gabriel-Lino-Garcia/FakeRecogna/raw/master/dataset/FakeRecogna.xlsx'\n",
    "alternative_df = pd.read_excel(dset_link, engine='openpyxl')  # engine para xlsx\n",
    "alternative_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa405200",
   "metadata": {},
   "source": [
    "#### Nulos\n",
    "Verificar presença de linha com campo 'Noticia' nulo e remover se for o caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b195a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Titulo         31\n",
       "Subtitulo    6323\n",
       "Noticia         1\n",
       "Categoria       1\n",
       "Data          352\n",
       "Autor          17\n",
       "URL             1\n",
       "Classe          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c7eb42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Subtitulo</th>\n",
       "      <th>Noticia</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Data</th>\n",
       "      <th>Autor</th>\n",
       "      <th>URL</th>\n",
       "      <th>Classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7337</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Titulo Subtitulo Noticia Categoria Data Autor  URL  Classe\n",
       "7337    NaN       NaN     NaN       NaN  NaN   NaN  NaN     NaN"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative_df[alternative_df['Noticia'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31970488",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_df.dropna(subset=['Noticia'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dfc6c",
   "metadata": {},
   "source": [
    "#### Preparação do segundo dataset\n",
    "\n",
    "Colunas de interesse são apenas 'notícia' (equivalente a 'lemma_str') e classe (equivalente a 'fake'). Note que, neste dataset, Classe 0.0 indica notícia Falsa e classe 1.0 indica notícia real! Portanto, é necessário adaptar o DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe4c87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_df['lemmas_str'] = alternative_df['Noticia']\n",
    "alternative_df['fake'] = (~alternative_df['Classe'].astype(bool)).astype(int) # inverter 1 e 0\n",
    "\n",
    "# Dropar colunas agora redundantes\n",
    "alternative_df = alternative_df.drop(['Noticia', 'Classe'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e850ae8",
   "metadata": {},
   "source": [
    "Amostrar 400 linhas para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ce06a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "sample_df = alternative_df.sample(n=n, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d822e44",
   "metadata": {},
   "source": [
    "#### Predição\n",
    "\n",
    "Aplicar TF-IDF para vetorizar, salvar dados no S3 e efetuar predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbc1cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "x_test_alt, y_test_alt = create_x_y_2(sample_df, tfidf)\n",
    "save_to_s3_bucket_as_libsvm(x_test_alt, y_test_alt, \n",
    "                            prefix='test', filename='model_2_alt.libsvm', tipo='modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0897774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_alt = make_prediction(xgb_predictor_2, model_name='model_2_alt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e863b",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4d9d8dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       205\n",
      "           1       0.49      1.00      0.66       195\n",
      "\n",
      "    accuracy                           0.49       400\n",
      "   macro avg       0.74      0.50      0.34       400\n",
      "weighted avg       0.75      0.49      0.33       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_alt, y_pred_alt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6701f20",
   "metadata": {},
   "source": [
    "#### Salvar predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63849f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_alt = pd.DataFrame({'pred_alt': y_pred_alt})\n",
    "df_pred_alt.to_csv(f's3://{BUCKET_MODEL}/test/pred_alt.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84883f14",
   "metadata": {},
   "source": [
    "### Encerrar modelo\n",
    "Após pegar métricas e dados de interesse, encerrar modelo para evitar cobranças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59db753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor_2.delete_endpoint(delete_endpoint_config=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
